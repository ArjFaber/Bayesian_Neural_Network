{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "\n",
    "silence_tensorflow()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(y_pred,y_true):\n",
    "    y_pred_flat = np.asarray(y_pred).flatten()\n",
    "    y_true_flat = np.asarray(y_true).flatten()\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of neural network according to Xavier initialization\n",
    "def init(shape):\n",
    "    return tf.random.truncated_normal(\n",
    "        shape, \n",
    "        mean=0.0,\n",
    "        stddev=np.sqrt(2/sum(shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDenseLayer(tf.keras.Model):\n",
    "    def __init__(self, input_data, output_data, name=None):\n",
    "        \n",
    "        super(BayesianDenseLayer, self).__init__(name=name)\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        \n",
    "        self.weight_loc = tf.Variable(init([input_data, output_data]), name='weight_loc')\n",
    "        self.weight_std = tf.Variable(init([input_data, output_data]) -6.0, name='weight_std')\n",
    "        self.bias_loc = tf.Variable(init([1, output_data]), name='bias_loc')\n",
    "        self.bias_std = tf.Variable(init([1, output_data])-6.0, name='bias_std')\n",
    "    \n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Perform the forward pass\"\"\"\n",
    "        \n",
    "        if sampling:\n",
    "        \n",
    "            # Flipout-estimated weight samples\n",
    "            s = tfp.random.rademacher(tf.shape(x))\n",
    "            r = tfp.random.rademacher([x.shape[0], self.output_data])\n",
    "            w_samples = tf.nn.softplus(self.weight_std)*tf.random.normal([self.input_data, self.output_data])\n",
    "            w_perturbations = r*tf.matmul(x*s, w_samples)\n",
    "            w_outputs = tf.matmul(x, self.weight_loc) + w_perturbations\n",
    "            \n",
    "            # Flipout-estimated bias samples\n",
    "            r = tfp.random.rademacher([x.shape[0], self.output_data])\n",
    "            b_samples = tf.nn.softplus(self.bias_std)*tf.random.normal([self.output_data])\n",
    "            b_outputs = self.bias_loc + r*b_samples\n",
    "            \n",
    "            return w_outputs + b_outputs\n",
    "        \n",
    "        else:\n",
    "            return x @ self.weight_loc + self.bias_loc\n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        weight = tfd.Normal(self.weight_loc, tf.nn.softplus(self.weight_std))\n",
    "        bias = tfd.Normal(self.bias_loc, tf.nn.softplus(self.bias_std))\n",
    "        prior = tfd.Normal(0, 1)\n",
    "        return (tf.reduce_sum(tfd.kl_divergence(weight, prior)) +\n",
    "                tf.reduce_sum(tfd.kl_divergence(bias, prior)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDenseNetwork(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, dims, name=None):\n",
    "        \n",
    "        super(BayesianDenseNetwork, self).__init__(name=name)\n",
    "        \n",
    "        self.steps = []\n",
    "        self.acts = []\n",
    "        for i in range(len(dims)-1):\n",
    "            self.steps += [BayesianDenseLayer(dims[i], dims[i+1])]\n",
    "            self.acts += [tf.nn.relu]\n",
    "            \n",
    "        self.acts[-1] = lambda x: x\n",
    "        \n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "\n",
    "        for i in range(len(self.steps)):\n",
    "            x = self.steps[i](x, sampling=sampling)\n",
    "            x = self.acts[i](x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        return tf.reduce_sum([s.losses for s in self.steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_Reg(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, dims, name=None):\n",
    "        \n",
    "        super(BNN_Reg, self).__init__(name=name)\n",
    "        \n",
    "        # Multilayer fully-connected neural network to predict mean\n",
    "        self.loc_mean = BayesianDenseNetwork(dims)\n",
    "        \n",
    "        # Variational distribution variables for observation error\n",
    "        self.std_alpha = tf.Variable([10.0], name='std_alpha')\n",
    "        self.std_beta = tf.Variable([10.0], name='std_beta')\n",
    "\n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \n",
    "        # Predict means\n",
    "        loc_preds = self.loc_mean(x, sampling=sampling)\n",
    "    \n",
    "        # Predict std deviation\n",
    "        post_dist = tfd.Gamma(self.std_alpha, self.std_beta)\n",
    "        adjust = lambda x: tf.sqrt(tf.math.reciprocal(x))\n",
    "        N = x.shape[0]\n",
    "        if sampling:\n",
    "            std_preds = adjust(post_dist.sample([N]))\n",
    "        else:\n",
    "            std_preds = tf.ones([N, 1])*adjust(post_dist.mean())\n",
    "    \n",
    "        # Return mean and std predictions\n",
    "        return tf.concat([loc_preds, std_preds], 1)\n",
    "    \n",
    "    \n",
    "    def ll(self, x, y, sampling=True):\n",
    "        mean_std = self.call(x, sampling=sampling)\n",
    "        return tfd.Normal(mean_std[:,0], mean_std[:,1]).log_prob(y[:,0])\n",
    "    \n",
    "    def Normal_Sampling(self, x):\n",
    "        preds = self.call(x)\n",
    "        return tfd.Normal(preds[:,0], preds[:,1]).sample()\n",
    "    \n",
    "    def sampling(self, x, n = 1):\n",
    "        sampling = np.zeros((x.shape[0], n))\n",
    "        for k in range(n_samples):\n",
    "            sampling[:,k] = self.Normal_Sampling(x)\n",
    "        return sampling\n",
    "    \n",
    "    @property\n",
    "    def loss(self):\n",
    "        \n",
    "        mean_loss = self.loc_mean.losses\n",
    "        post_dist = tfd.Gamma(self.std_alpha, self.std_beta)\n",
    "        prior = tfd.Gamma(10.0, 10.0)\n",
    "        std_loss = tfd.kl_divergence(post_dist, prior)\n",
    "\n",
    "        # Return the sum of both\n",
    "        return mean_loss + std_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(model, optimizer, x_data, y_data, N):  \n",
    "    #calculating lower bound (elbo method)\n",
    "    with tf.GradientTape() as gradtape:\n",
    "        ll = model.ll(x_data, y_data)\n",
    "        model_loss = model.loss \n",
    "        train_cost = model_loss/N - tf.reduce_mean(ll)\n",
    "    derivatives = gradtape.gradient(train_cost, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(derivatives, model.trainable_variables))\n",
    "    return train_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(model, optimizer, cycles, train_data, test_data, N):\n",
    "    train_elbo = np.zeros(cycles)\n",
    "    mse_root = []\n",
    "    y_pred = []; y = []\n",
    "    for ep in range(cycles):\n",
    "            #Update weights each batch\n",
    "        for X_values, y_values in train_data:\n",
    "            train_elbo[ep] += process(model, optimizer, X_values, y_values, N)  \n",
    "\n",
    "    # Evaluate performance on validation data\n",
    "        for X_values, y_values in test_data:\n",
    "            y_pred.append(model(X_values, sampling=False)[:, 0])\n",
    "            y.append(y_values)\n",
    "        mse_root.append(calc_rmse(np.asarray(y_pred), np.asarray(y)))\n",
    "    return mse_root[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_ds = pd.read_csv(\"seattle-weather.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.029432</td>\n",
       "      <td>16.439083</td>\n",
       "      <td>8.234771</td>\n",
       "      <td>3.241136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.680194</td>\n",
       "      <td>7.349758</td>\n",
       "      <td>5.023004</td>\n",
       "      <td>1.437825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-7.100000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.800000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.900000</td>\n",
       "      <td>35.600000</td>\n",
       "      <td>18.300000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precipitation     temp_max     temp_min         wind\n",
       "count    1461.000000  1461.000000  1461.000000  1461.000000\n",
       "mean        3.029432    16.439083     8.234771     3.241136\n",
       "std         6.680194     7.349758     5.023004     1.437825\n",
       "min         0.000000    -1.600000    -7.100000     0.400000\n",
       "25%         0.000000    10.600000     4.400000     2.200000\n",
       "50%         0.000000    15.600000     8.300000     3.000000\n",
       "75%         2.800000    22.200000    12.200000     4.000000\n",
       "max        55.900000    35.600000    18.300000     9.500000"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_ds = weather_ds\n",
    "weather_ds_copy = weather_ds\n",
    "data_dummies = weather_ds_copy.drop(columns=['date', 'precipitation', 'temp_max', 'temp_min', 'wind' ])\n",
    "data_dummies = pd.get_dummies(data=data_dummies).astype(int)\n",
    "weather_ds_copy = weather_ds_copy[['precipitation', 'wind', 'temp_min', 'temp_max']]\n",
    "weather_ds = pd.concat([data_dummies,weather_ds_copy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_drizzle</th>\n",
       "      <th>weather_fog</th>\n",
       "      <th>weather_rain</th>\n",
       "      <th>weather_snow</th>\n",
       "      <th>weather_sun</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>wind</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weather_drizzle  weather_fog  weather_rain  weather_snow  weather_sun  \\\n",
       "0                1            0             0             0            0   \n",
       "1                0            0             1             0            0   \n",
       "2                0            0             1             0            0   \n",
       "3                0            0             1             0            0   \n",
       "4                0            0             1             0            0   \n",
       "\n",
       "   precipitation  wind  temp_min  temp_max  \n",
       "0            0.0   4.7       5.0      12.8  \n",
       "1           10.9   4.5       2.8      10.6  \n",
       "2            0.8   2.3       7.2      11.7  \n",
       "3           20.3   4.7       5.6      12.2  \n",
       "4            1.3   6.1       2.8       8.9  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(weather_ds[['weather_drizzle','weather_fog', 'weather_rain', 'weather_snow', 'weather_sun','precipitation', 'wind', 'temp_min']])\n",
    "y = np.asarray(weather_ds['temp_max'])\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Fold_Cross_Validation(cycles, learning_rate, l1_neurons, n_folds = 5):\n",
    "    performance = []          \n",
    "   \n",
    "    kf = KFold(n_splits =n_folds, shuffle = True, random_state = 42)\n",
    "    test_index_set = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        test_index_set += 1\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "          \n",
    "        N_train = x_train.shape[0]\n",
    "        N_val = x_test.shape[0]\n",
    "        # Make y 2d\n",
    "        y_train = np.expand_dims(y_train, 1)\n",
    "        y_test = np.expand_dims(y_test, 1)\n",
    "        data_train = tf.data.Dataset.from_tensors((x_train, y_train))\n",
    "        data_test = tf.data.Dataset.from_tensors((x_test, y_test))\n",
    "        BNN_model = BNN_Reg([np.shape(X)[1], l1_neurons, 1])\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate= learning_rate) #gradient descent\n",
    "        root_mse = perform(BNN_model, optimizer, cycles, data_train, data_test, x_train.shape[0])\n",
    "        performance.append(root_mse)\n",
    "        print(f\"Fold: {test_index_set}\")\n",
    "        print(f\"Root MSE: {root_mse}\")\n",
    "\n",
    "    print(\"Mean Performance:\", np.mean(performance))\n",
    "\n",
    "    return np.mean(performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hl_nodes': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'epochs': [50, 287, 525, 762, 1000], 'learning_rate': [0.01, 0.00505, 0.0001]}\n"
     ]
    }
   ],
   "source": [
    "#Number of nodes in the hidden layer:\n",
    "hl_nodes = [int(x) for x in np.linspace(10,100, num = 10)]\n",
    "#Number of learning cycles:\n",
    "epochs = [int(x) for x in np.linspace(50,1000, num = 5)]\n",
    "#learning_rate\n",
    "learning_rate = [float(x) for x in np.linspace(0.01,0.0001, num = 3)] \n",
    "random_grid = {'hl_nodes': hl_nodes,\n",
    "               'epochs' : epochs,\n",
    "               'learning_rate': learning_rate\n",
    "               }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_BNN(hl_nodes,epochs,learning_rate):\n",
    "    info = []\n",
    "    for nodes in hl_nodes:\n",
    "        for eps in epochs:\n",
    "            for lr in learning_rate:\n",
    "                rmse = K_Fold_Cross_Validation(eps, lr, nodes)\n",
    "                info.append(rmse)\n",
    "                print(\"Processed %0.3f out of %0.3f elements\" % (len(info),len(epochs)*len(hl_nodes)*len(learning_rate)))\n",
    "\n",
    "    opt = np.min(info,axis = 0)\n",
    "    return print(\"Number of nodes: %0.3f, number of learning cycles: %0.3f, learning rate: %0.3f\" %(opt[1], opt[2], opt[3]))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Root MSE: 9.59655475616455\n",
      "Fold: 2\n",
      "Root MSE: 7.054793834686279\n",
      "Fold: 3\n",
      "Root MSE: 8.04556941986084\n",
      "Fold: 4\n",
      "Root MSE: 9.502260208129883\n",
      "Fold: 5\n",
      "Root MSE: 10.311676979064941\n",
      "Mean Performance: 8.902171\n",
      "Processed 1.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 4.697515487670898\n",
      "Fold: 2\n",
      "Root MSE: 4.1003947257995605\n",
      "Fold: 3\n",
      "Root MSE: 4.252614974975586\n",
      "Fold: 4\n",
      "Root MSE: 4.507584571838379\n",
      "Fold: 5\n",
      "Root MSE: 3.7096540927886963\n",
      "Mean Performance: 4.2535524\n",
      "Processed 2.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 15.406168937683105\n",
      "Fold: 2\n",
      "Root MSE: 15.32197093963623\n",
      "Fold: 3\n",
      "Root MSE: 13.83474063873291\n",
      "Fold: 4\n",
      "Root MSE: 8.856071472167969\n",
      "Fold: 5\n",
      "Root MSE: 19.63810157775879\n",
      "Mean Performance: 14.61141\n",
      "Processed 3.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 5.1722211837768555\n",
      "Fold: 2\n",
      "Root MSE: 4.801832675933838\n",
      "Fold: 3\n",
      "Root MSE: 5.718461990356445\n",
      "Fold: 4\n",
      "Root MSE: 5.352035045623779\n",
      "Fold: 5\n",
      "Root MSE: 5.3212127685546875\n",
      "Mean Performance: 5.273153\n",
      "Processed 4.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 3.6130764484405518\n",
      "Fold: 2\n",
      "Root MSE: 3.2402873039245605\n",
      "Fold: 3\n",
      "Root MSE: 3.5813729763031006\n",
      "Fold: 4\n",
      "Root MSE: 3.4667625427246094\n",
      "Fold: 5\n",
      "Root MSE: 3.7434606552124023\n",
      "Mean Performance: 3.5289922\n",
      "Processed 5.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 6.925521373748779\n",
      "Fold: 2\n",
      "Root MSE: 7.458442687988281\n",
      "Fold: 3\n",
      "Root MSE: 6.392644882202148\n",
      "Fold: 4\n",
      "Root MSE: 12.125530242919922\n",
      "Fold: 5\n",
      "Root MSE: 9.70873737335205\n",
      "Mean Performance: 8.522175\n",
      "Processed 6.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 4.239192008972168\n",
      "Fold: 2\n",
      "Root MSE: 4.23822546005249\n",
      "Fold: 3\n",
      "Root MSE: 4.068105220794678\n",
      "Fold: 4\n",
      "Root MSE: 4.073634624481201\n",
      "Fold: 5\n",
      "Root MSE: 3.902761459350586\n",
      "Mean Performance: 4.104384\n",
      "Processed 7.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 3.2941606044769287\n",
      "Fold: 2\n",
      "Root MSE: 3.3369617462158203\n",
      "Fold: 3\n",
      "Root MSE: 3.3042614459991455\n",
      "Fold: 4\n",
      "Root MSE: 3.1783552169799805\n",
      "Fold: 5\n",
      "Root MSE: 3.1850361824035645\n",
      "Mean Performance: 3.259755\n",
      "Processed 8.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 6.616501808166504\n",
      "Fold: 2\n",
      "Root MSE: 8.024731636047363\n",
      "Fold: 3\n",
      "Root MSE: 6.325477123260498\n",
      "Fold: 4\n",
      "Root MSE: 7.125021457672119\n",
      "Fold: 5\n",
      "Root MSE: 5.473845481872559\n",
      "Mean Performance: 6.7131157\n",
      "Processed 9.000 out of 150.000 elements\n",
      "Fold: 1\n",
      "Root MSE: 3.7292063236236572\n",
      "Fold: 2\n",
      "Root MSE: 3.8753468990325928\n",
      "Fold: 3\n",
      "Root MSE: 3.943526268005371\n",
      "Fold: 4\n",
      "Root MSE: 4.095051288604736\n"
     ]
    }
   ],
   "source": [
    "random_search_BNN(hl_nodes,epochs,learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
